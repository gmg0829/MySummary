ROC曲线则是从阈值选取角度出发来研究学习器泛化性能的有力工具。

若我们更重视“查准率”，则可以把阈值设置的大一些，让分类器的预测结果更有把握；若我们更重视“查全率”，则可以把阈值设置的小一些，让分类器预测出更多的正例。


ROC曲线的纵轴是“真正例率”(True Positive Rate, 简称TPR)，横轴是“假正例率”(False Positive Rate,简称FPR)。

## ROC曲线的意义
- ROC曲线能很容易的查出任意阈值对学习器的泛化性能影响。
- 有助于选择最佳的阈值。ROC曲线越靠近左上角，模型的准确性就越高。最靠近左上角的ROC曲线上的点是分类错误最少的最好阈值，其假正例和假反例总数最少。
- 可以对不同的学习器比较性能。将各个学习器的ROC曲线绘制到同一坐标中，直观地鉴别优劣，靠近左上角的ROC曲所代表的学习器准确性最高。

## AUC

ROC曲线下的面积，即AUC(Area Under ROC Curve)。AUC就是ROC曲线下的面积，衡量学习器优劣的一种性能指标。
AUC是衡量二分类模型优劣的一种评价指标，表示预测的正例排在负例前面的概率。

ROC曲线用在多分类中是没有意义的。

- AUC ＝ 1，代表完美分类器
- 0.5 < AUC < 1，优于随机分类器
- 0 < AUC < 0.5，差于随机分类器

### TPR和FPR
考虑一个二分问题，即将实例分成正类（positive）或负类（negative）。对一个二分问题来说，会出现四种情况。如果一个实例是正类并且也被 预测成正类，即为真正类（True positive）,如果实例是负类被预测成正类，称之为假正类（False positive）。相应地，如果实例是负类被预测成负类，称之为真负类（True negative）,正类被预测成负类则为假负类（false negative）。

TP：正确肯定的数目；

FN：漏报，没有正确找到的匹配的数目；

FP：误报，给出的匹配是不正确的；

TN：正确拒绝的非匹配对数；

真正类率(true positive rate ,TPR), 计算公式为TPR=TP/ (TP+ FN)，刻画的是分类器所识别出的 正实例占所有正实例的比例。另外一个是假正类率(false positive rate, FPR),计算公式为FPR= FP / (FP + TN)，计算的是分类器错认为正类的负实例占所有负实例的比例。



